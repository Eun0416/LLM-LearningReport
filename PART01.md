# 용어 정리

### 생성형 AI (Generative AI)
- 인공지능의 한 분야로, 기존의 데이터를 학습하여 새로운 텍스트, 이미지, 음악, 비디오 등의 콘텐츠를 창조하는 기술.

### 거대 언어 모델 (LLM: Large Language Model)
- 방대한 양의 텍스트 데이터를 학습하여 인간과 유사한 자연어 이해 및 생성 능력을 갖춘 인공지능 모델. ChatGPT, Gemini 등이 대표적임.

### 자연어 처리 (NLP: Natural Language Processing)
- 컴퓨터가 인간의 언어를 이해하고 분석하며 생성할 수 있도록 하는 인공지능의 한 분야.

### GPT (Generative Pre-trained Transformer)
- OpenAI에서 개발한 트랜스포머 아키텍처 기반의 거대 언어 모델 시리즈. 사전 학습과 미세 조정을 통해 다양한 자연어 처리 task를 수행함.

### 사전 훈련 (Pre-training)
- 모델이 방대한 양의 일반적인 텍스트 데이터를 학습하여 언어의 기본적인 패턴과 문맥을 이해하는 과정

### 미세 조정 (Fine-tuning)
- 사전 훈련된 모델을 특정 작업이나 데이터셋에 맞춰 추가적으로 학습시켜 성능을 향상시키는 과정.

### ChatGPT
- OpenAI에서 개발한 GPT 모델 기반의 대화형 인공지능 챗봇 서비스. 질문 응답, 텍스트 생성, 번역, 코딩 등 다양한 기능을 제공함.

### 멀티모달 (Multimodal)
- 하나의 AI 모델이 텍스트, 이미지, 오디오, 비디오 등 여러 종류의 데이터를 동시에 처리하고 이해할 수 있는 능력.

### RLHF(Reinforcement Learning from Human Feedback)
- 인간의 피드백을 보상으로 사용하여 인공지능 모델을 학습시키는 강화 학습 방법. ChatGPT의 답변 품질 향상에 기여함.

### 환각현상 (Hallucination)
- 거대 언어 모델이 사실에 기반하지 않은 정보를 그럴듯하게 생성하여 답변하는 현상.

### OpenAI
- 인공지능 기술을 연구하고 개발하는 미국의 연구 기업. ChatGPT, GPT 모델 시리즈 등을 개발함.

### 트랜스포머 (Transformar)
- 자연어 처리 분야에서 혁신적인 성능을 보인 딥러닝 모델 아키텍처. 병렬 처리와 장거리 의존성 모델링에 강점을 가짐.
